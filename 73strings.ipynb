{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "73strings.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQlCiXwrqJhC9MsNxSlgl0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkeeg/Python-codes/blob/master/73strings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiNJzoXQKR8q"
      },
      "source": [
        "from google.colab  import files\n",
        "# Upload following files: Occupation Data.xlsx,Skills.xlsx,Technology Skills.xlsx, Tools Used.xlsx\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yifc1gkZNehY",
        "cellView": "both"
      },
      "source": [
        "import pandas as pd\n",
        "#Read Files Occupation Data,Skills. In Skills file retain only those skills whose importance is \n",
        "#greater than a threshold value. \n",
        "df_occ = pd.read_excel(r'Occupation Data.xlsx')\n",
        "df_skls = pd.read_excel(r'Skills.xlsx',usecols = ['Title','Element Name','Scale ID','Data Value'])\n",
        "df_skls = df_skls.loc[((df_skls['Data Value']>4.0) & (df_skls['Scale ID']=='IM'))]\n",
        "df_skls.drop(['Scale ID','Data Value'],axis=1,inplace=True)\n",
        " \n",
        "#Grouping the dataframe by Title column so that all skills for a particular Title are\n",
        "#arranged as columns.\n",
        "s = df_skls.groupby('Title').cumcount().add(1)\n",
        "df_skls = (df_skls.set_index(['Title',s]).unstack().sort_index(axis=1,level=1))\n",
        "df_skls.columns = ['{}_{}'.format(a, b) for a,b in df_skls.columns]\n",
        "df_skls = df_skls.reset_index()\n",
        "df_skls.dropna(axis=1,how='all',inplace=True)\n",
        "\n",
        " \n",
        "#Read Technology skills file. Retain only those entries which are hot skills\n",
        "df_tecskls = pd.read_excel(r'Technology Skills.xlsx',usecols=['Title','Example','Hot Technology'])\n",
        "#df_tecskls = df_tecskls.loc[(df_tecskls['Hot Technology']=='Y')]\n",
        "df_tecskls.drop(['Hot Technology'],axis=1,inplace=True)\n",
        " \n",
        "#Grouping by Title and arranging tech skills as columns\n",
        "t = df_tecskls.groupby('Title').cumcount().add(1)\n",
        "df_tecskls = (df_tecskls.set_index(['Title',t]).unstack().sort_index(axis=1,level=1))\n",
        "df_tecskls.columns = ['{}_{}'.format(a, b) for a,b in df_tecskls.columns]\n",
        "df_tecskls = df_tecskls.reset_index()\n",
        "df_tecskls.dropna(axis=1,how='all',inplace=True)\n",
        "\n",
        " \n",
        "#Read 'Tools Used' file. \n",
        "df_tools = pd.read_excel(r'Tools Used.xlsx',usecols=['Title','Example'])\n",
        "\n",
        "#rename column name 'Example' to 'Tools'\n",
        "df_tools.rename(columns={'Example':'Tools'},inplace=True) \n",
        "#grouping by Title and arranging Tools uses as columns\n",
        "u = df_tools.groupby('Title').cumcount().add(1)\n",
        "df_tools = (df_tools.set_index(['Title',u]).unstack().sort_index(axis=1,level=1))\n",
        "df_tools.columns = ['{}_{}'.format(a, b) for a,b in df_tools.columns]\n",
        "df_tools = df_tools.reset_index()\n",
        "df_tools.dropna(axis=1,how='all',inplace=True)\n",
        " \n",
        "#Merging 3 data frames by performing an outer join on 'Title' column\n",
        "df_skills = pd.merge(df_tools,df_tecskls,on='Title',how='outer')\n",
        "df_skills = pd.merge(df_skills,df_skls,on='Title',how='outer')\n",
        "df_skills.dropna(axis=1,how='all',inplace=True)\n",
        "\n",
        "#Remove columns which have very few rows\n",
        "cols =[]\n",
        "for col,count in dict(df_skills.count()).items():\n",
        "  if count<10:\n",
        "    cols.append(col)\n",
        "\n",
        "df_skills.drop(columns=cols,inplace=True)\n",
        "\n",
        "#Replacing NaNs with blank spaces\n",
        "df_skills.fillna(\"\",inplace=True)\n",
        "\n",
        "#Store Job title and skills in different dataframes\n",
        "X=df_skills['Title'].copy()\n",
        "y = df_skills.copy()\n",
        "y.drop(columns=['Title'],inplace=True)\n",
        "\n",
        "#Import necessary modules\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer,LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "import re\n",
        "import openpyxl\n",
        "\n",
        "#Pipeline to vectorize and build Job Title-> Skills prediction model\n",
        "pipeline1 = Pipeline([('cvr', CountVectorizer(stop_words='english',ngram_range=(1,2))),\n",
        "                     ('clf', MultiOutputClassifier(MultinomialNB()))])\n",
        "\n",
        "#Convert y to numpy array for compatibility with binarizer\n",
        "y=y.to_numpy()\n",
        "\n",
        "#Binarize the labels using Multilabel binarizer\n",
        "mulbi = MultiLabelBinarizer()\n",
        "y= mulbi.fit_transform(y)\n",
        "\n",
        "#Convert y(labels) back to dataframe\n",
        "y = pd.DataFrame(y)\n",
        "\n",
        "#Performing KFold cross validation\n",
        "kf = KFold(n_splits=10,shuffle=True)\n",
        "\n",
        "for train_idx,test_idx in kf.split(X,y):\n",
        "  X_train,X_test = X.iloc[train_idx],X.iloc[test_idx]\n",
        "  y_train,y_test = y.iloc[train_idx],y.iloc[test_idx]\n",
        "  #Train the model\n",
        "  print(\"Training model 1...\")\n",
        "  pipeline1.fit(X_train, y_train)\n",
        "  #Predict\n",
        "  pred = pipeline1.predict(X_test)\n",
        "\n",
        "\n",
        "################## Processing the file containing job description and title ########################\n",
        "\n",
        "#Store description and Job title if different Dataframes\n",
        "X_jd = df_occ['Description'].copy()\n",
        "y_jd = df_occ['Title'].copy()\n",
        "\n",
        "#Pipeline to vectorize and build Description->Job Title prediction model\n",
        "pipeline2 = Pipeline([('cvr',TfidfVectorizer(stop_words='english',ngram_range=(1,3),max_df=0.85)),\n",
        "                     ('clf',LinearSVC(max_iter=2000))])\n",
        "\n",
        "\n",
        "#Performing KFold cross validation\n",
        "kf = KFold(n_splits=10,shuffle=True)\n",
        "\n",
        "for train_idx,test_idx in kf.split(X_jd,y_jd):\n",
        "  X_trainjd,X_testjd = X_jd.iloc[train_idx],X_jd.iloc[test_idx]\n",
        "  y_trainjd,y_testjd = y_jd.iloc[train_idx],y_jd.iloc[test_idx]\n",
        "  #Train the model\n",
        "  print(\"Training model 2...\")\n",
        "  pipeline2.fit(X_trainjd, y_trainjd)\n",
        "\n",
        "  #Predict Title\n",
        "  pred_jt = pipeline2.predict(X_testjd)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0U-JmzSfLCl"
      },
      "source": [
        "# Upload test file 'Test_file.xlsx' for prediction\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRWnvHClSTH3",
        "cellView": "both"
      },
      "source": [
        "#Run this cell to make predictions for the test file\n",
        "############################ Predict from test file ################################\n",
        "df_test = pd.read_excel(r'Test_file.xlsx')\n",
        "\n",
        "#Predict Job Title from Description using pipeline2\n",
        "jt = pipeline2.predict(df_test['Description'])\n",
        "\n",
        "#Predict Skills from Job Title using pipeline1\n",
        "#apply inverse transform method to retrieve predicted text labels\n",
        "skills = mulbi.inverse_transform(pipeline1.predict(jt))\n",
        "\n",
        "#Arraning Data in final DataFrame\n",
        "df_fin = pd.DataFrame(columns=['Description','Title','Tags'])\n",
        "df_fin['Description'] = df_test['Description']\n",
        "df_fin['Title'] = jt.copy()\n",
        "\n",
        "#Populate Skills column using the predicted skills\n",
        "#Predicted skills are in a list, so unpack them in each row\n",
        "df_fin['Tags'] = [x for x in skills]\n",
        "\n",
        "#Removing paranthesis, single quotes and comma in the beginning of the string\n",
        "df_fin['Tags']=df_fin['Tags'].apply(lambda x: re.sub(r'[()]','',str(x)))\n",
        "df_fin['Tags']=df_fin['Tags'].apply(lambda x: re.sub(r\"'\",'',str(x)))\n",
        "df_fin['Tags']=df_fin['Tags'].apply(lambda x: re.sub(r\"^[,]\",'',str(x)))\n",
        "\n",
        "#Process final submission file to User's system\n",
        "df_fin.to_excel('Final_file.xlsx',sheet_name='final',index=False)\n",
        "\n",
        "#Setting column width for output file using openpyxl\n",
        "wb = openpyxl.load_workbook('Final_file.xlsx')\n",
        "sheet = wb.active\n",
        "# set the width of the column \n",
        "sheet.column_dimensions['A'].width = 50\n",
        "sheet.column_dimensions['B'].width = 50\n",
        "sheet.column_dimensions['C'].width = 50\n",
        "wb.save('Final_file.xlsx')\n",
        "\n",
        "#Download to user's system\n",
        "files.download('Final_file.xlsx') \n",
        "\n",
        "#Delete test file from colab to enable uploading another test file\n",
        "#with different job descriptions\n",
        "!rm Test_file.xlsx\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}